<!DOCTYPE html>
<!-- this file is auto-generated from webgl/lessons/webgl-gpgpu.md. Do not edited directly -->
<!--
Copyright 2012, Gregg Tavares.
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

*   Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

*   Redistributions in binary form must reproduce the above
    copyright notice, this list of conditions and the following disclaimer
    in the documentation and/or other materials provided with the
    distribution.

*   Neither the name of Gregg Tavares. nor the names of his
    contributors may be used to endorse or promote products derived from
    this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-->
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="How to do general computing with WebGL">
<meta name="keywords" content="webgl graphics">
<meta name="thumbnail" content="https://webglfundamentals.org/webgl/lessons/screenshots/webgl-gpgpu_en.jpg">

<meta property="og:title" content="WebGL GPGPU">
<meta property="og:type" content="website">
<meta property="og:image" content="https://webglfundamentals.org/webgl/lessons/screenshots/webgl-gpgpu_en.jpg">
<meta property="og:description" content="How to do general computing with WebGL">
<meta property="og:url" content="https://webglfundamentals.org/webgl/lessons/webgl-gpgpu.html">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@greggman">
<meta name="twitter:creator" content="@greggman">
<meta name="twitter:domain" content="webglfundamentals.org">
<meta name="twitter:title" content="WebGL GPGPU">
<meta name="twitter:url" content="https://webglfundamentals.org/webgl/lessons/webgl-gpgpu.html">
<meta name="twitter:description" content="How to do general computing with WebGL">
<meta name="twitter:image:src" content="https://webglfundamentals.org/webgl/lessons/screenshots/webgl-gpgpu_en.jpg">

<script type="application/ld+json">
{
  "@context":"https://schema.org",
  "@graph":[
    {
      "@type":"WebSite",
      "@id":"https://webglfundamentals.org/#website",
      "url":"https://webglfundamentals.org/",
      "name":"WebglFundamentals"
    },
    {
      "@type":"ImageObject",
      "@id":"https://webglfundamentals.org/webgl/lessons/webgl-gpgpu.html#primaryimage",
      "url":"https://webglfundamentals.org/webgl/lessons/screenshots/webgl-gpgpu_en.jpg",
      "width":1200,
      "height":630
    },
    {
      "@type":"WebPage",
      "@id":"https://webglfundamentals.org/webgl/lessons/webgl-gpgpu.html#webpage",
      "url":"https://webglfundamentals.org/webgl/lessons/webgl-gpgpu.html",
      "inLanguage":"en",
      "name":"WebGL GPGPU",
      "keywords":"webgl graphics programming",
      "isPartOf":{
        "@id":"https://webglfundamentals.org/#website"
      },
      "primaryImageOfPage":{
        "@id":"https://webglfundamentals.org/webgl/lessons/webgl-gpgpu.html#primaryimage"
      }
    }
  ]
}
</script>


<title>WebGL GPGPU</title>
<link href="/webgl/lessons/resources/webglfundamentals-icon.png" rel="shortcut icon" type="image/png">
<link rel="stylesheet" href="/webgl/lessons/lang.css">
<link rel="stylesheet" href="/webgl/lessons/resources/lesson.css">

  <link rel="alternate" hreflang="en" href="https://webglfundamentals.org/webgl/lessons/webgl-gpgpu.html">
  <link rel="alternate" hreflang="fr" href="https://webglfundamentals.org/webgl/lessons/fr/webgl-gpgpu.html">
  <link rel="alternate" hreflang="ja" href="https://webglfundamentals.org/webgl/lessons/ja/webgl-gpgpu.html">
  <link rel="alternate" hreflang="ko" href="https://webglfundamentals.org/webgl/lessons/ko/webgl-gpgpu.html">
  <link rel="alternate" hreflang="pl" href="https://webglfundamentals.org/webgl/lessons/pl/webgl-gpgpu.html">
  <link rel="alternate" hreflang="pt-br" href="https://webglfundamentals.org/webgl/lessons/pt-br/webgl-gpgpu.html">
  <link rel="alternate" hreflang="ru" href="https://webglfundamentals.org/webgl/lessons/ru/webgl-gpgpu.html">
  <link rel="alternate" hreflang="zh_cn" href="https://webglfundamentals.org/webgl/lessons/zh_cn/webgl-gpgpu.html">




</head>
<body>
<div class="webgl_navbar">
  <div>
    <select class="language">
    <option value="/webgl/lessons/webgl-gpgpu.html" selected>English</a>
    <option value="/webgl/lessons/fr/webgl-gpgpu.html" >Français</a>
    <option value="/webgl/lessons/ja/webgl-gpgpu.html" >日本語</a>
    <option value="/webgl/lessons/ko/webgl-gpgpu.html" >한국어</a>
    <option value="/webgl/lessons/pl/webgl-gpgpu.html" >Polski</a>
    <option value="/webgl/lessons/pt-br/webgl-gpgpu.html" >Portuguese</a>
    <option value="/webgl/lessons/ru/webgl-gpgpu.html" >Русский</a>
    <option value="/webgl/lessons/zh_cn/webgl-gpgpu.html" >简体中文</a>
</select>


    <a href="#toc">Table of Contents</a>
  </div>
</div>
<div class="webgl_header">
  <h1><a href="/">WebGLFundamentals.org</a></h1>
<style>
#forkongithub>div {
    background: #000;
    color: #fff;
    font-family: arial,sans-serif;
    text-align: center;
    font-weight: bold;
    padding: 5px 40px;
    font-size: 0.9rem;
    line-height: 1.3rem;
    position: relative;
    transition: 0.5s;
    display: block;
    width: 400px;
    position: absolute;
    top: 0;
    right: 0;
    transform: translateX(200px) rotate(45deg) translate(10px,70px);
    box-shadow: 4px 4px 10px rgba(0,0,0,0.8);
    pointer-events: auto;
}
#forkongithub a {
  text-decoration: none;
  color: #fff;
}
#forkongithub>div:hover {
    background: #c11;
    color: #fff;
}
#forkongithub .contributors {
  font-size: 0.75rem;
  background: rgba(255,255,255,0.2);
  line-height: 1.2;
  padding: 0.1em;
}
#forkongithub>div::before,#forkongithub>div::after {
    content: "";
    width: 100%;
    display: block;
    position: absolute;
    top: 1px;
    left: 0;
    height: 1px;
    background: #fff;
}
#forkongithub>div::after {
    bottom: 1px;
    top: auto;
}

#forkongithub{
    z-index: 9999;
    /* needed for firefox */
    overflow: hidden;
    width: 300px;
    height: 300px;
    position: absolute;
    right: 0;
    top: 0;
    pointer-events: none;
}
#forkongithub svg{
  width: 1em;
  height: 1em;
  vertical-align: middle;
}
#forkongithub img {
  width: 1em;
  height: 1em;
  border-radius: 100%;
  vertical-align: middle;
}

@media (max-width: 900px) {
    #forkongithub>div {
        line-height: 1.2rem;
    }
}
@media (max-width: 700px) {
  #forkongithub {
    display: none;
  }
}
@media (max-width: 410px) {
    #forkongithub>div {
        font-size: 0.7rem;
        transform: translateX(150px) rotate(45deg) translate(20px,40px);
    }
}

</style>
<div id="forkongithub"><div><div><a href="https://github.com/gfxfundamentals/webgl-fundamentals">Fix, Fork, Contribute <?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg width="100%" height="100%" viewBox="0 0 136 133" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
    <g transform="matrix(3.92891,0,0,3.92891,67.867,129.125)">
        <path d="M0,-31.904C-8.995,-31.904 -16.288,-24.611 -16.288,-15.614C-16.288,-8.417 -11.621,-2.312 -5.148,-0.157C-4.333,-0.008 -4.036,-0.511 -4.036,-0.943C-4.036,-1.329 -4.05,-2.354 -4.058,-3.713C-8.589,-2.729 -9.545,-5.897 -9.545,-5.897C-10.286,-7.779 -11.354,-8.28 -11.354,-8.28C-12.833,-9.29 -11.242,-9.27 -11.242,-9.27C-9.607,-9.155 -8.747,-7.591 -8.747,-7.591C-7.294,-5.102 -4.934,-5.821 -4.006,-6.238C-3.858,-7.29 -3.438,-8.008 -2.972,-8.415C-6.589,-8.826 -10.392,-10.224 -10.392,-16.466C-10.392,-18.244 -9.757,-19.698 -8.715,-20.837C-8.883,-21.249 -9.442,-22.905 -8.556,-25.148C-8.556,-25.148 -7.188,-25.586 -4.076,-23.478C-2.777,-23.84 -1.383,-24.02 0.002,-24.026C1.385,-24.02 2.779,-23.84 4.08,-23.478C7.19,-25.586 8.555,-25.148 8.555,-25.148C9.444,-22.905 8.885,-21.249 8.717,-20.837C9.761,-19.698 10.392,-18.244 10.392,-16.466C10.392,-10.208 6.583,-8.831 2.954,-8.428C3.539,-7.925 4.06,-6.931 4.06,-5.411C4.06,-3.234 4.04,-1.477 4.04,-0.943C4.04,-0.507 4.333,0 5.16,-0.159C11.628,-2.318 16.291,-8.419 16.291,-15.614C16.291,-24.611 8.997,-31.904 0,-31.904" style="fill:white;"/>
    </g>
</svg>
</a></div></div></div>

</div>


<div class="container">
  <div class="lesson-title">
    <h1>WebGL GPGPU</h1>
  </div>
  <div class="lesson">
    <div class="lesson-main">
      <p>GPGPU is &quot;General Purpose&quot; GPU and means using the GPU for something
other than drawing pixels.</p>
<p>The basic realization to understanding GPGPU in WebGL is that a texture
is not an image, it&#39;s a 2D array of values. In <a href="webgl-3d-textures.html">the article on textures</a>
we covered reading from a texture. In <a href="webgl-render-to-texture.html">the article on rendering to a texture</a>
we covered writing to a texture. So, if realizing a texture is a 2D array of values
we can say that we have really described a way to read from and write to 2D arrays.
That is the essence of GPGPU in WebGL.</p>
<p>In JavaScript there is the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map"><code class="notranslate" translate="no">Array.prototype.map</code></a> function which given an array calls a function on each element </p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function multBy2(v) {
  return v * 2;
}

const src = [1, 2, 3, 4, 5, 6];
const dst = src.map(multBy2);

// dst is now [2, 4, 6, 8, 10, 12];
</code></pre>
<p>You can consider <code class="notranslate" translate="no">multBy2</code> a shader and <code class="notranslate" translate="no">map</code> similar to calling <code class="notranslate" translate="no">gl.drawArrays</code> or <code class="notranslate" translate="no">gl.drawElements</code>.
Some differences.</p>
<h2 id="shaders-don-t-generate-a-new-array-you-have-to-provide-one">Shaders don&#39;t generate a new array, you have to provide one</h2>
<p>We can simulate that by making our own map function</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function multBy2(v) {
  return v * 2;
}

+function mapSrcToDst(src, fn, dst) {
+  for (let i = 0; i &lt; src.length; ++i) {
+    dst[i] = fn(src[i]);
+  }
+}

const src = [1, 2, 3, 4, 5, 6];
-const dst = src.map(multBy2);
+const dst = new Array(6);    // to simulate that in WebGL we have to allocate a texture
+mapSrcToDst(src, multBy2, dst);

// dst is now [2, 4, 6, 8, 10, 12];
</code></pre>
<h2 id="shader-s-don-t-return-a-value-they-set-gl_fragcolor-">Shader&#39;s don&#39;t return a value they set <code class="notranslate" translate="no">gl_FragColor</code></h2>
<p>That&#39;s pretty easy to simulate</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">+let gl_FragColor;

function multBy2(v) {
-  return v * 2;
+  gl_FragColor = v * 2;
}

function mapSrcToDst(src, fn, dst) {
  for (let i = 0; i &lt; src.length; ++i) {
-    dst[i] = fn(src[i]);
+    fn(src[i]);
+    dst[i] = gl_FragColor;
  }
}

const src = [1, 2, 3, 4, 5, 6];
const dst = new Array(6);    // to simulate that in WebGL we have to allocate a texture
mapSrcToDst(src, multBy2, dst);

// dst is now [2, 4, 6, 8, 10, 12];
</code></pre>
<h2 id="shaders-are-destination-based-not-source-based-">Shaders are destination based, not source based.</h2>
<p>In other words, they loop over the destination and ask &quot;what value should I put here&quot;</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">let gl_FragColor;

function multBy2(src) {
-  gl_FragColor = v * 2;
+  return function(i) {
+    gl_FragColor = src[i] * 2;
+  }
}

-function mapSrcToDst(src, fn, dst) {
-  for (let i = 0; i &lt; src.length; ++i) {
-    fn(src[i]);
+function mapDst(dst, fn) {
+  for (let i = 0; i &lt; dst.length; ++i) {    
+    fn(i);
    dst[i] = gl_FragColor;
  }
}

const src = [1, 2, 3, 4, 5, 6];
const dst = new Array(6);    // to simulate that in WebGL we have to allocate a texture
mapDst(dst, multBy2(src));

// dst is now [2, 4, 6, 8, 10, 12];
</code></pre>
<h2 id="in-webgl-the-index-or-id-of-the-pixel-who-s-value-you-re-being-asked-to-provide-is-called-gl_fragcoord-">In WebGL the index or ID of the pixel who&#39;s value you&#39;re being asked to provide is called <code class="notranslate" translate="no">gl_FragCoord</code></h2>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">let gl_FragColor;
+let gl_FragCoord;

function multBy2(src) {
-  return function(i) {
-    gl_FragColor = src[i] * 2;
+  return function() {
+    gl_FragColor = src[gl_FragCoord] * 2;
  }
}

function mapDst(dst, fn) {
  for (let i = 0; i &lt; dst.length; ++i) {    
-    fn(i);
+    gl_FragCoord = i;
+    fn();
    dst[i] = gl_FragColor;
  }
}

const src = [1, 2, 3, 4, 5, 6];
const dst = new Array(6);    // to simulate that in WebGL we have to allocate a texture
mapDst(dst, multBy2(src));

// dst is now [2, 4, 6, 8, 10, 12];
</code></pre>
<h2 id="in-webgl-textures-are-2d-arrays-">In WebGL textures are 2D arrays.</h2>
<p>Let&#39;s assume our <code class="notranslate" translate="no">dst</code> array represents a 3x2 texture</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">let gl_FragColor;
let gl_FragCoord;

function multBy2(src, across) {
  return function() {
-    gl_FragColor = src[gl_FragCoord] * 2;
+    gl_FragColor = src[gl_FragCoord.y * across + gl_FragCoord.x] * 2;
  }
}

-function mapDst(dst, fn) {
-  for (let i = 0; i &lt; dst.length; ++i) {    
-    gl_FragCoord = i;
-    fn();
-    dst[i] = gl_FragColor;
-  }
-}
function mapDst(dst, across, up, fn) {
  for (let y = 0; y &lt; up; ++y) {
    for (let x = 0; x &lt; across; ++x) {
      gl_FragCoord = {x, y};
      fn();
      dst[y * across + x] = gl_FragColor;
    }
  }
}

const src = [1, 2, 3, 4, 5, 6];
const dst = new Array(6);    // to simulate that in WebGL we have to allocate a texture
mapDst(dst, 2, 3, multBy2(src));

// dst is now [2, 4, 6, 8, 10, 12];
</code></pre>
<p>And we could keep going. I&#39;m hoping the examples above helps you see that GPGPU in WebGL
is pretty simple conceptually. Let&#39;s actually do the above in WebGL.</p>
<p>To understand the following code you will, at a minimum, need to have read
&quot;<a href="webgl-fundamentals.org">the article on fundamentals</a>&quot;, probably the article on 
&quot;<a href="webgl-how-it-works">How It Works</a>&quot;, and &quot;<a href="webgl-3d-textures.html">the article on textures</a>.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const vs = `
attribute vec4 position;
void main() {
  gl_Position = position;
}
`;

const fs = `
precision highp float;

uniform sampler2D srcTex;
uniform vec2 srcDimensions;

void main() {
  vec2 texcoord = gl_FragCoord.xy / srcDimensions;
  vec4 value = texture2D(srcTex, texcoord);
  gl_FragColor = value * 2.0;
}
`;

const dstWidth = 3;
const dstHeight = 2;

// make a 3x2 canvas for 6 results
const canvas = document.createElement(&#39;canvas&#39;);
canvas.width = dstWidth;
canvas.height = dstHeight;

const gl = canvas.getContext(&#39;webgl&#39;);

const program = webglUtils.createProgramFromSources(gl, [vs, fs]);
const positionLoc = gl.getAttribLocation(program, &#39;position&#39;);
const srcTexLoc = gl.getUniformLocation(program, &#39;srcTex&#39;);
const srcDimensionsLoc = gl.getUniformLocation(program, &#39;srcDimensions&#39;);

// setup a full canvas clip space quad
const buffer = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
  -1, -1,
   1, -1,
  -1,  1,
  -1,  1,
   1, -1,
   1,  1,
]), gl.STATIC_DRAW);

// setup our attributes to tell WebGL how to pull
// the data from the buffer above to the position attribute
gl.enableVertexAttribArray(positionLoc);
gl.vertexAttribPointer(
    positionLoc,
    2,         // size (num components)
    gl.FLOAT,  // type of data in buffer
    false,     // normalize
    0,         // stride (0 = auto)
    0,         // offset
);

// create our source texture
const srcWidth = 3;
const srcHeight = 2;
const tex = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, tex);
gl.pixelStorei(gl.UNPACK_ALIGNMENT, 1); // see https://webglfundamentals.org/webgl/lessons/webgl-data-textures.html
gl.texImage2D(
    gl.TEXTURE_2D,
    0,                // mip level
    gl.LUMINANCE,     // internal format
    srcWidth,
    srcHeight,
    0,                // border
    gl.LUMINANCE,     // format
    gl.UNSIGNED_BYTE, // type
    new Uint8Array([
      1, 2, 3,
      4, 5, 6,
    ]));
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

gl.useProgram(program);
gl.uniform1i(srcTexLoc, 0);  // tell the shader the src texture is on texture unit 0
gl.uniform2f(srcDimensionsLoc, srcWidth, srcHeight);

gl.drawArrays(gl.TRIANGLES, 0, 6);  // draw 2 triangles (6 vertices)

// get the result
const results = new Uint8Array(dstWidth * dstHeight * 4);
gl.readPixels(0, 0, dstWidth, dstHeight, gl.RGBA, gl.UNSIGNED_BYTE, results);

// print the results
for (let i = 0; i &lt; dstWidth * dstHeight; ++i) {
  log(results[i * 4]);
}
</code></pre>
<p>and here it is running</p>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-mult-by-2.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-mult-by-2.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<p>Some notes about the code above.</p>
<ul>
<li><p>We draw a clip space -1 to +1 quad.</p>
<p>We create vertices for a -1 to +1 quad from 2 triangles. This means, assuming the viewport
is set correctly, we&#39;ll draw all the pixels in the destination. In other words we&#39;ll ask
our shader to generate a value for every element in the result array. That array in
this case is the canvas itself.</p>
</li>
<li><p><code class="notranslate" translate="no">gl_FragCoord</code> is a pixel coordinate but textures are referenced by texture coordinates.</p>
<p>This means to look up a value in <code class="notranslate" translate="no">srcTex</code> we need to translate from pixels to texture coordinates.
That is this line.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">vec2 texcoord = gl_FragCoord.xy / srcDimensions;
</code></pre>
</li>
<li><p>Shaders output 4 values per pixel</p>
<p>In this particular case this affects how we read the output. We ask for <code class="notranslate" translate="no">RGBA/UNSIGNED_BYTE</code>
from <code class="notranslate" translate="no">readPixels</code> <a href="webgl-readpixels.html">because other format/type combinations are not supported</a>.
So we have to look at every 4th value for our answer.</p>
<p>Note: It would be smart to try to take advantage of the fact that WebGL does 4 values at a time
to go even faster.</p>
</li>
<li><p>Both our input data and output data are <code class="notranslate" translate="no">UNSIGNED_BYTE</code> values</p>
<p>The means we can only pass in and get back integer values between 0 and 255.
We could use different formats for input by supplying a texture of a different format.
We could also try rendering to a texture of a different format for more range of values.</p>
</li>
</ul>
<p>In the example above src and dst are the same size. Let&#39;s change it so we add every 2 values
from src to make dst. In other words, given <code class="notranslate" translate="no">[1, 2, 3, 4, 5, 6]</code> as input we want
<code class="notranslate" translate="no">[3, 7, 11]</code> as output. And further, let&#39;s keep the source as 3x2 data</p>
<p>To get an arbitrary value from a texture we need to generate texture coordinates.
The basic formula to get a value from a 2D array as though it was a 1D array is</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">y = floor(indexInto1DArray / width);
x = indexInto1DArray % width;
</code></pre>
<p>For textures we&#39;d then need to translate that value into a texture coordinate which is</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">vec2 texcoord = (vec2(x, y) + 0.5) / dimensionsOfTexture;
</code></pre>
<p>See <a href="webgl-skinning.html#texel-coords">this</a>) for more info on why the + 0.5</p>
<p>Given that, our shader needs to change to this to add every 2 values.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">precision highp float;

uniform sampler2D srcTex;
uniform vec2 srcDimensions;
uniform vec2 dstDimensions;

vec4 getValueFrom2DTextureAs1DArray(sampler2D tex, vec2 dimensions, float index) {
  float y = floor(index / dimensions.x);
  float x = mod(index, dimensions.x);
  vec2 texcoord = (vec2(x, y) + 0.5) / dimensions;
  return texture2D(tex, texcoord);
}

void main() {
  // compute a 1D index into dst
  vec2 dstPixel = floor(gl_FragCoord.xy);  // see https://webglfundamentals.org/webgl/lessons/webgl-shadertoy.html#pixel-coords
  float dstIndex = dstPixel.y * dstDimensions.x + dstPixel.x;

  vec4 v1 = getValueFrom2DTextureAs1DArray(srcTex, srcDimensions, dstIndex * 2.0);
  vec4 v2 = getValueFrom2DTextureAs1DArray(srcTex, srcDimensions, dstIndex * 2.0 + 1.0);

  gl_FragColor = v1 + v2;
}
</code></pre>
<p>The function <code class="notranslate" translate="no">getValueFrom2DTextureAs1DArray</code> is basically our array accessor
function. That means these 2 lines</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">  vec4 v1 = getValueFrom2DTextureAs1DArray(srcTex, srcDimensions, dstIndex * 2.0);
  vec4 v2 = getValueFrom2DTextureAs1DArray(srcTex, srcDimensions, dstIndex * 2.0 + 1.0);
</code></pre>
<p>Effectively mean this</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">  vec4 v1 = srcTexAs1DArray[dstIndex * 2.0];
  vec4 v2 = setTexAs1DArray[dstIndex * 2.0 + 1.0];
</code></pre>
<p>In our JavaScript we need to lookup the location of <code class="notranslate" translate="no">dstDimensions</code></p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const program = webglUtils.createProgramFromSources(gl, [vs, fs]);
const positionLoc = gl.getAttribLocation(program, &#39;position&#39;);
const srcTexLoc = gl.getUniformLocation(program, &#39;srcTex&#39;);
const srcDimensionsLoc = gl.getUniformLocation(program, &#39;srcDimensions&#39;);
+const dstDimensionsLoc = gl.getUniformLocation(program, &#39;dstDimensions&#39;);
</code></pre>
<p>and set it</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">gl.useProgram(program);
gl.uniform1i(srcTexLoc, 0);  // tell the shader the src texture is on texture unit 0
gl.uniform2f(srcDimensionsLoc, srcWidth, srcHeight);
+gl.uniform2f(dstDimensionsLoc, dstWidth, dstHeight);
</code></pre>
<p>and we need to change the size of the destination (the canvas)</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const dstWidth = 3;
-const dstHeight = 2;
+const dstHeight = 1;
</code></pre>
<p>and with that we have now have the result array able to do math
with random access into the source array</p>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-add-2-elements.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-add-2-elements.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<p>If you wanted to use more arrays as input just add more textures</p>
<h2 id="first-example-particles">First example: particles</h2>
<p>Let&#39;s say you have a very simple particle system.
Every particle just has a position and a velocity and
if it goes off one edge of the screen it wraps around to
the other side.</p>
<p>Given most of the other articles on this site you&#39;d
update the positions of the particles in JavaScript</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">for (const particle of particles) {
  particle.pos.x = (particle.pos.x + particle.velocity.x) % canvas.width;
  particle.pos.y = (particle.pos.y + particle.velocity.y) % canvas.height;
}
</code></pre>
<p>and then draw the particles either one at a time</p>
<pre class="prettyprint notranslate" translate="no"><code class="notranslate" translate="no">useProgram (particleShader)
setup particle attributes
for each particle
  set uniforms
  draw particle
</code></pre><p>Or you might upload all the new particle positions</p>
<pre class="prettyprint notranslate" translate="no"><code class="notranslate" translate="no">bindBuffer(..., particlePositionBuffer)
bufferData(..., latestParticlePositions, ...)
useProgram (particleShader)
setup particle attributes
set uniforms
draw particles
</code></pre><p>In <a href="webgl-pulling-vertices.html">the article on pulling vertices</a>
we covered storing positions in textures. If we store both the
positions and velocities in textures then we can use the GPGPU techniques
above to update the particle positions in a shader</p>
<p>Before we get started, to make it easy, we want to use floating point
textures. Those are an optional feature of WebGL. Most devices can
read floating point textures. Desktops can render
to floating point textures but most smartphones can not.</p>
<p>Also in order to support pulling vertices we need to check vertex shaders can use
textures which is also an optional feature. We should probably check exactly
how many are supported. In this case we will only need to use one texture
in the vertex shader so we just check that a least 1 is supported.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// Get A WebGL context
/** @type {HTMLCanvasElement} */
const canvas = document.querySelector(&quot;#canvas&quot;);
const gl = canvas.getContext(&quot;webgl&quot;);
if (!gl) {
  return;
}
+// check we can use floating point textures
+const ext1 = gl.getExtension(&#39;OES_texture_float&#39;);
+if (!ext1) {
+  alert(&#39;Need OES_texture_float&#39;);
+  return;
+}
+// check we can render to floating point textures
+const ext2 = gl.getExtension(&#39;WEBGL_color_buffer_float&#39;);
+if (!ext2) {
+  alert(&#39;Need WEBGL_color_buffer_float&#39;);
+  return;
+}
+// check we can use textures in a vertex shader
+if (gl.getParameter(gl.MAX_VERTEX_TEXTURE_IMAGE_UNITS) &lt; 1) {
+  alert(&#39;Can not use textures in vertex shaders&#39;);
+  return;
+}
</code></pre>
<p>Here&#39;s the fragment shader to update the particle positions</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">precision highp float;

uniform sampler2D positionTex;
uniform sampler2D velocityTex;
uniform vec2 texDimensions;
uniform vec2 canvasDimensions;
uniform float deltaTime;

vec2 euclideanModulo(vec2 n, vec2 m) {
    return mod(mod(n, m) + m, m);
}

void main() {
  // compute texcoord from gl_FragCoord;
  vec2 texcoord = gl_FragCoord.xy / texDimensions;

  vec2 position = texture2D(positionTex, texcoord).xy;
  vec2 velocity = texture2D(velocityTex, texcoord).xy;
  vec2 newPosition = euclideanModulo(position + velocity * deltaTime, canvasDimensions);

  gl_FragColor = vec4(newPosition, 0, 1);
}
</code></pre>
<p>There will be one velocity per position so the velocity texture and position texture
are the same size. Further, we&#39;re generating new positions into a texture
so we know our destination texture is also the same size
as our source which means we can use <code class="notranslate" translate="no">texDimensions</code> for all 3 textures.</p>
<p>In the shader below we use a vertex id, something we covered in
<a href="webgl-drawing-without-data.html">the article on drawing without data</a>.
Using that id we pull positions out of the textures (our arrays) 
similar to the article on <a href="webgl-pulling-vertices.html">pulling-vertices</a>.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">attribute float id;
uniform sampler2D positionTex;
uniform vec2 texDimensions;
uniform mat4 matrix;

vec4 getValueFrom2DTextureAs1DArray(sampler2D tex, vec2 dimensions, float index) {
  float y = floor(index / dimensions.x);
  float x = mod(index, dimensions.x);
  vec2 texcoord = (vec2(x, y) + 0.5) / dimensions;
  return texture2D(tex, texcoord);
}

void main() {
  // pull the position from the texture
  vec4 position = getValueFrom2DTextureAs1DArray(positionTex, texDimensions, id);

  // do the common matrix math
  gl_Position = matrix * vec4(position.xy, 0, 1);
  gl_PointSize = 10.0;
}
</code></pre>
<p>So then we need 3 textures, one for velocities, 2 for positions. Why 2 for positions?
Because you can not write to the same texture you&#39;re reading from. So, we&#39;ll
effectively do</p>
<pre class="prettyprint notranslate" translate="no"><code class="notranslate" translate="no">newPositions = oldPositions + velocities
</code></pre><p>Then we&#39;ll swap <code class="notranslate" translate="no">newPositions</code> and <code class="notranslate" translate="no">oldPositions</code> each frame.</p>
<p>Here&#39;s the code to make the position and velocity textures.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// create random positions and velocities.
const rand = (min, max) =&gt; {
  if (max === undefined) {
    max = min;
    min = 0;
  }
  return Math.random() * (max - min) + min;
};
const positions = new Float32Array(
    ids.map(_ =&gt; [rand(canvas.width), rand(canvas.height), 0, 0]).flat());
const velocities = new Float32Array(
    ids.map(_ =&gt; [rand(-300, 300), rand(-300, 300), 0, 0]).flat());

function createTexture(gl, data, width, height) {
  const tex = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, tex);
  gl.texImage2D(
      gl.TEXTURE_2D,
      0,        // mip level
      gl.RGBA,  // internal format
      width,
      height,
      0,        // border
      gl.RGBA,  // format
      gl.FLOAT, // type
      data,
  );
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  return tex;
}

// create a texture for the velocity and 2 textures for the positions.
const velocityTex = createTexture(gl, velocities, particleTexWidth, particleTexHeight);
const positionTex1 = createTexture(gl, positions, particleTexWidth, particleTexHeight);
const positionTex2 = createTexture(gl, null, particleTexWidth, particleTexHeight);
</code></pre>
<p>We also need framebuffers like we covered in <a href="webgl-render-to-texture.html">the article on rendering to a texture</a>. We&#39;ll make 2. One that allows us to write to
one position texture and another for the other position texture.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">function createFramebuffer(gl, tex) {
  const fb = gl.createFramebuffer();
  gl.bindFramebuffer(gl.FRAMEBUFFER, fb);
  gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, tex, 0);
  return fb;
}

// create 2 framebuffers. One that renders to positionTex1 one
// and another that renders to positionTex2

const positionsFB1 = createFramebuffer(gl, positionTex1);
const positionsFB2 = createFramebuffer(gl, positionTex2);

let oldPositionsInfo = {
  fb: positionsFB1,
  tex: positionTex1,
};
let newPositionsInfo = {
  fb: positionsFB2,
  tex: positionTex2,
};
</code></pre>
<p>we also need to setup a buffer of vertex ids for our vertex pulling particle
drawing shader.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// setup an id buffer
const particleTexWidth = 20;
const particleTexHeight = 10;
const numParticles = particleTexWidth * particleTexHeight;
const ids = new Array(numParticles).fill(0).map((_, i) =&gt; i);
const idBuffer = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, idBuffer);
gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(ids), gl.STATIC_DRAW);
</code></pre>
<p>And we need to compile both sets of shaders and look up all the locations</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const updatePositionProgram = webglUtils.createProgramFromSources(
    gl, [updatePositionVS, updatePositionFS]);
const drawParticlesProgram = webglUtils.createProgramFromSources(
    gl, [drawParticlesVS, drawParticlesFS]);

const updatePositionPrgLocs = {
  position: gl.getAttribLocation(updatePositionProgram, &#39;position&#39;),
  positionTex: gl.getUniformLocation(updatePositionProgram, &#39;positionTex&#39;),
  velocityTex: gl.getUniformLocation(updatePositionProgram, &#39;velocityTex&#39;),
  texDimensions: gl.getUniformLocation(updatePositionProgram, &#39;texDimensions&#39;),
  canvasDimensions: gl.getUniformLocation(updatePositionProgram, &#39;canvasDimensions&#39;),
  deltaTime: gl.getUniformLocation(updatePositionProgram, &#39;deltaTime&#39;),
};

const drawParticlesProgLocs = {
  id: gl.getAttribLocation(drawParticlesProgram, &#39;id&#39;),
  positionTex: gl.getUniformLocation(drawParticlesProgram, &#39;positionTex&#39;),
  texDimensions: gl.getUniformLocation(drawParticlesProgram, &#39;texDimensions&#39;),
  matrix: gl.getUniformLocation(drawParticlesProgram, &#39;matrix&#39;),
};
</code></pre>
<p>And then at render time, first we run the position updating shader to generate
new positions.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">let then = 0;
function render(time) {
  // convert to seconds
  time *= 0.001;
  // Subtract the previous time from the current time
  const deltaTime = time - then;
  // Remember the current time for the next frame.
  then = time;

  webglUtils.resizeCanvasToDisplaySize(gl.canvas);

  // render to the new positions
  gl.bindFramebuffer(gl.FRAMEBUFFER, newPositionsInfo.fb);
  gl.viewport(0, 0, particleTexWidth, particleTexHeight);

  // setup our attributes to tell WebGL how to pull
  // the data from the buffer above to the position attribute
  // this buffer just contains a -1 to +1 quad for rendering
  // to every pixel
  gl.bindBuffer(gl.ARRAY_BUFFER, updatePositionBuffer);
  gl.enableVertexAttribArray(updatePositionPrgLocs.position);
  gl.vertexAttribPointer(
      updatePositionPrgLocs.position,
      2,         // size (num components)
      gl.FLOAT,  // type of data in buffer
      false,     // normalize
      0,         // stride (0 = auto)
      0,         // offset
  );

  gl.activeTexture(gl.TEXTURE0);
  gl.bindTexture(gl.TEXTURE_2D, oldPositionsInfo.tex);
  gl.activeTexture(gl.TEXTURE0 + 1);
  gl.bindTexture(gl.TEXTURE_2D, velocityTex);

  gl.useProgram(updatePositionProgram);
  gl.uniform1i(updatePositionPrgLocs.positionTex, 0);  // tell the shader the position texture is on texture unit 0
  gl.uniform1i(updatePositionPrgLocs.velocityTex, 1);  // tell the shader the position texture is on texture unit 1
  gl.uniform2f(updatePositionPrgLocs.texDimensions, particleTexWidth, particleTexHeight);
  gl.uniform2f(updatePositionPrgLocs.canvasDimensions, gl.canvas.width, gl.canvas.height);
  gl.uniform1f(updatePositionPrgLocs.deltaTime, deltaTime);

  gl.drawArrays(gl.TRIANGLES, 0, 6);  // draw 2 triangles (6 vertices)
</code></pre>
<p>Then we use those new positions to draw points for the particles</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
  gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);

  // setup our attributes to tell WebGL how to pull
  // the data from the buffer above to the id attribute
  gl.bindBuffer(gl.ARRAY_BUFFER, idBuffer);
  gl.enableVertexAttribArray(drawParticlesProgLocs.id);
  gl.vertexAttribPointer(
      drawParticlesProgLocs.id,
      1,         // size (num components)
      gl.FLOAT,  // type of data in buffer
      false,     // normalize
      0,         // stride (0 = auto)
      0,         // offset
  );

  gl.activeTexture(gl.TEXTURE0);
  gl.bindTexture(gl.TEXTURE_2D, newPositionsInfo.tex);

  gl.useProgram(drawParticlesProgram);
  gl.uniform2f(drawParticlesProgLocs.texDimensions, particleTexWidth, particleTexWidth);
  gl.uniform1i(drawParticlesProgLocs.positionTex, 0);  // tell the shader the position texture is on texture unit 0
  gl.uniformMatrix4fv(
      drawParticlesProgLocs.matrix,
      false,
      m4.orthographic(0, gl.canvas.width, 0, gl.canvas.height, -1, 1));

  gl.drawArrays(gl.POINTS, 0, numParticles);
</code></pre>
<p>Finally we swap the variables tracking the old and new positions
so our new positions this frame will be the old positions next frame.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">  // swap which texture we will read from
  // and which one we will write to
  {
    const temp = oldPositionsInfo;
    oldPositionsInfo = newPositionsInfo;
    newPositionsInfo = temp;
  }
</code></pre>
<p>And with the we get GPGPU based particles. JavaScript is doing almost no
work except calling <code class="notranslate" translate="no">gl.drawArrays</code> twice. Once to update the positions,
and once to draw the particles</p>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-particles.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-particles.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<p>We&#39;re drawing 200 particles by having position and velocity textures 20x10 pixels big. What if we wanted to draw 199 particles? Since WebGL only works with textures
and textures are 2D arrays we can&#39;t make a 2D array that is 199 pixels. Instead
though we could compute 200 but only draw 199. You&#39;ll need to find similar
solutions for problems that don&#39;t neatly fit into a 2D array.</p>
<h2 id="next-example-finding-the-closest-line-segment-to-a-point">Next Example: Finding the closest line segment to a point</h2>
<p>I&#39;m not sure this is a good example but it&#39;s the one I wrote. I say it might
not be good because I suspect there are better algorithms for finding
the closest line to a point than brute force, checking every line with the point. For example various space partitioning algorithms might let you easily discard 95%
of the points and so be faster. Still, this example probably does show
some techniques of GPGPU at least.</p>
<p>The problem: We have 500 points and 1000 line segments. For each point
find which line segment it is closest to. The brute force method is</p>
<pre class="prettyprint notranslate" translate="no"><code class="notranslate" translate="no">for each point
  minDistanceSoFar = MAX_VALUE
  for each line segment
    compute distance from point to line segment
    if distance is &lt; minDistanceSoFar
       minDistanceSoFar = distance
       closestLine = line segment
</code></pre><p>For 500 points each checking 1000 lines that&#39;s 500,000 checks.
Modern GPUs have 100s or 1000s of cores so if we could do this on
the GPU we could potentially run hundreds or thousands of times faster.</p>
<p>Again we&#39;ll put our data in textures. One texture for the points,
One texture for the both the starting point and ending point of each line segment.
And, one texture to write the ID of the closest line for each point.</p>
<p>Here&#39;s the fragment shader that finds the closest line for a single point.
It&#39;s exactly the brute force algorithm as above</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">  function closestLineFS(numLineSegments) {
    return `
precision highp float;

uniform sampler2D pointsTex;
uniform vec2 pointsTexDimensions;
uniform sampler2D linesTex;
uniform vec2 linesTexDimensions;

vec4 getAs1D(sampler2D tex, vec2 dimensions, float index) {
  float y = floor(index / dimensions.x);
  float x = mod(index, dimensions.x);
  vec2 texcoord = (vec2(x, y) + 0.5) / dimensions;
  return texture2D(tex, texcoord);
}

// from https://stackoverflow.com/a/6853926/128511
// a is the point, b,c is the line segment
float distanceFromPointToLine(in vec3 a, in vec3 b, in vec3 c) {
  vec3 ba = a - b;
  vec3 bc = c - b;
  float d = dot(ba, bc);
  float len = length(bc);
  float param = 0.0;
  if (len != 0.0) {
    param = clamp(d / (len * len), 0.0, 1.0);
  }
  vec3 r = b + bc * param;
  return distance(a, r);
}

void main() {
  // gl_FragCoord is the coordinate of the pixel that is being set by the fragment shader.
  // It is the center of the pixel so the bottom left corner pixel will be (0.5, 0.5).
  // the pixel to the left of that is (1.5, 0.5), The pixel above that is (0.5, 1.5), etc...
  // so we can compute back into a linear index 
  float ndx = floor(gl_FragCoord.y) * pointsTexDimensions.x + floor(gl_FragCoord.x); 

  // find the closest line segment
  float minDist = 10000000.0; 
  float minIndex = -1.0;
  vec3 point = getAs1D(pointsTex, pointsTexDimensions, ndx).xyz;
  for (int i = 0; i &lt; ${numLineSegments}; ++i) {
    vec3 lineStart = getAs1D(linesTex, linesTexDimensions, float(i * 2)).xyz;
    vec3 lineEnd = getAsID(linesTex, linesTexDimensions, float(i * 2 + 1)).xyz;
    float dist = distanceFromPointToLine(point, lineStart, lineEnd);
    if (dist &lt; minDist) {
      minDist = dist;
      minIndex = float(i);
    }
  }

  // convert to 8bit color. The canvas defaults to RGBA 8bits per channel
  // so take our integer index (minIndex) and convert to float values that
  // will end up as the same 32bit index when read via readPixels as
  // 32bit values.
  gl_FragColor = vec4(
    mod(minIndex, 256.0),
    mod(floor(minIndex / 256.0), 256.0),
    mod(floor(minIndex / (256.0 * 256.0)), 256.0) ,
    floor(minIndex / (256.0 * 256.0 * 256.0))) / 255.0;
}
`;
  }
</code></pre>
<p>I renamed <code class="notranslate" translate="no">getValueFrom2DTextureAs1DArray</code> to <code class="notranslate" translate="no">getAs1D</code> just to make
some of the lines shorter and more readable.</p>
<p>The first thing to notice is we need to generate the shader. Shaders in WebGL1
have to have constant integer expression loops so we can&#39;t pass in the number
of line segments, we have to hard code it into the shader.</p>
<p>Otherwise it&#39;s a pretty straight forward implemenation of the brute force algorithm
we wrote above.</p>
<p><code class="notranslate" translate="no">pointsTex</code> contains the points. <code class="notranslate" translate="no">linesTex</code> contains the points for the
line segment in pairs, first point, followed by second point.</p>
<p>To use let&#39;s switch to using the helpers from
<a href="webgl-less-code-more-fun.html">less code more fun</a> otherwise things are
going to get too verbose.</p>
<p>First let&#39;s make some test data. Here&#39;s 2 points and 5 lines. They are
padded with 0, 0 because each one will stored in an RGBA texture.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const points = [
  100, 100, 0, 0,
  200, 100, 0, 0,
];
const lines = [
   25,  50,   0, 0,
   25, 150,   0, 0,
   90,  50,   0, 0,
   90, 150,   0, 0,
  125,  50,   0, 0,
  125, 150,   0, 0,
  185,  50,   0, 0,
  185, 150,   0, 0,
  225,  50,   0, 0,
  225, 150,   0, 0,
];
const numPoints = points.length / 4;
const numLineSegments = lines.length / 4 / 2;
</code></pre>
<p>If we plot those out they look like this</p>
<p><img src="resources/line-segments-points.svg" style="width: 500px;" class="webgl_center"></p>
<p>The lines are numbered 0 to 4 from left to right,
so if our code works the first point (<span style="color: red;">red</span>)
should get a value of 1 as the closest line, the second point
(<span style="color: green;">green</span>), should get a value of 3.</p>
<p>Let&#39;s put that data into textures.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const {tex: pointsTex, dimensions: pointsTexDimensions} =
    createDataTexture(gl, points, gl.FLOAT);
const {tex: linesTex, dimensions: linesTexDimensions} =
    createDataTexture(gl, lines, gl.FLOAT);

function createDataTexture(gl, data, type) {
  const numElements = data.length / 4;

  // compute a size that will hold all of our data
  const width = Math.ceil(Math.sqrt(numElements));
  const height = Math.ceil(numElements / width);

  const bin = type === gl.FLOAT
      ? new Float32Array(width * height * 4)
      : new Uint8Array(width * height * 4);
  bin.set(data);

  const tex = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, tex);
  gl.texImage2D(
      gl.TEXTURE_2D,
      0,        // mip level
      gl.RGBA,  // internal format
      width,
      height,
      0,        // border
      gl.RGBA,  // format
      type,     // type
      bin,
  );
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  return {tex, dimensions: [width, height]};
}
</code></pre>
<p>In this case we&#39;re letting the code choose the dimensions of the texture
and letting it pad the texture out. For example if we gave it an array
with 7 entries it would stick that in a 3x3 texture. It returns
both the texture and the dimensions it chose. Why do we let it choose
the dimension? Because textures have a maximum dimension.</p>
<p>Ideally we&#39;d just like to look at our data as a 1 dimensional array
of positions, 1 dimensional array of line points etc. So we could just
declare a texture to be Nx1. Unfortunately GPUs have a maximum
dimension and that can be as lowe as 1024 or 2048. If the limit
was 1024 and we needed 1025 values in our array we&#39;d have to put the data
in a texture like say 513x2. By putting the data in a square we won&#39;t
hit the limit until we hit the maximum texture dimension squared.
For a dimension limit of 1024 that would allow arrays of over 1 million values.</p>
<p>In any case now that we know how many line segments there are we can generate
the appropriate shader</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const closestLinePrgInfo = webglUtils.createProgramInfo(
    gl, [closestLineVS, closestLineFS(numLineSegments)]);
</code></pre>
<p>We also need a texture for the result and a framebuffer to attach it to. This
time since we only need an integer result for each point, the id of the closest
line segment, we can use an RGBA/UNSIGNED_BYTE texture. You can see at the end
of the shader we encode the id of the closest line segment into an 8bit RGBA
color</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// create a texture for the results
const {tex: closestLinesTex, dimensions: closestLinesTexDimensions} =
    createDataTexture(gl, new Array(numPoints * 4), gl.UNSIGNED_BYTE);

function createFramebuffer(gl, tex) {
  const fb = gl.createFramebuffer();
  gl.bindFramebuffer(gl.FRAMEBUFFER, fb);
  gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, tex, 0);
  return fb;
}

// create a framebuffer so we can write to the closestLinesTex
const closestLineFB = createFramebuffer(gl, closestLinesTex);
</code></pre>
<p>We still need a -1 to +1 quad to tell WebGL to render all the pixels
in the result</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// setup a full canvas clip space quad
const quadBufferInfo = webglUtils.createBufferInfoFromArrays(gl, {
  position: {
    numComponents: 2,
    data: [
      -1, -1,
       1, -1,
      -1,  1,
      -1,  1,
       1, -1,
       1,  1,
    ],
  },
});
</code></pre>
<p>Then we can render</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// compute the closest lines
gl.bindFramebuffer(gl.FRAMEBUFFER, closestLineFB);
gl.viewport(0, 0, ...closestLinesTexDimensions);

// setup our attributes to tell WebGL how to pull
// the data from the buffer above to the position attribute
// this buffer just contains a -1 to +1 quad for rendering
// to every pixel
webglUtils.setBuffersAndAttributes(gl, closestLinePrgInfo, quadBufferInfo);
gl.useProgram(closestLinePrgInfo.program);
webglUtils.setUniforms(closestLinePrgInfo, {
  pointsTex,
  pointsTexDimensions,
  linesTex,
  linesTexDimensions,
});
gl.drawArrays(gl.TRIANGLES, 0, 6);  // draw the clip space quad so we get one result for each pixel
</code></pre>
<p>and finally read the result</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">{
  const [width, height] = closestLinesTexDimensions;
  const pixels = new Uint8Array(width * height * 4);
  gl.readPixels(0, 0, width, height, gl.RGBA, gl.UNSIGNED_BYTE, pixels);

  // get a view of the pixels as 32bit unsigned integers
  const results = new Uint32Array(pixels.buffer);
  console.log(results);
}
</code></pre>
<p>If we run it</p>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-closest-line-results.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-closest-line-results.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<p>We should get the expected result of <code class="notranslate" translate="no">[1, 3]</code></p>
<p>Reading data back from the GPU is slow. Let&#39;s say we wanted to
visualize the results. It would be pretty easy to read those results
and draw them using canvas2D but how about with WebGL? Let&#39;s use
the data as is and draw the results?</p>
<p>First, drawing the points is relatively easy. Like in the particle example
above we pass in an id for each point to the vertex shader
and use that to get points. Let&#39;s draw each point in a different
color so we can highlight the closest line in the same color.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const drawPointsVS = `
attribute float a_id;
uniform float numPoints;
uniform sampler2D pointsTex;
uniform vec2 pointsTexDimensions;
uniform mat4 matrix;

varying vec4 v_color;

vec4 getAs1D(sampler2D tex, vec2 dimensions, float index) {
  float y = floor(index / dimensions.x);
  float x = mod(index, dimensions.x);
  vec2 texcoord = (vec2(x, y) + 0.5) / dimensions;
  return texture2D(tex, texcoord);
}

// converts hue, saturation, and value each in the 0 to 1 range
// to rgb.  c = color, c.x = hue, c.y = saturation, c.z = value
vec3 hsv2rgb(vec3 c) {
  c = vec3(c.x, clamp(c.yz, 0.0, 1.0));
  vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
  vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
  return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
}

void main() {
  // pull the position from the texture
  vec4 position = getAs1D(pointsTex, pointsTexDimensions, a_id);

  // do the common matrix math
  gl_Position = matrix * vec4(position.xy, 0, 1);
  gl_PointSize = 5.0;

  float hue = a_id / numPoints;
  v_color = vec4(hsv2rgb(vec3(hue, 1, 1)), 1);
}
`;
</code></pre>
<p>Rather than passing in colors we generate them using <code class="notranslate" translate="no">hsv2rgb</code> and passing it
a hue from to 0 to 1. For 500 points there would
be no easy way to tell lines apart but for around 10 points we should be
able to distinguish them.</p>
<p>We pass the generated color to a simple fragment shader</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const drawClosestPointsLinesFS = `
precision highp float;
varying vec4 v_color;
void main() {
  gl_FragColor = v_color;
}
`;
</code></pre>
<p>To draw all the lines, even the ones that are not close to any points is
almost the same except we don&#39;t generate a color. In this case we&#39;re just
using a hardcoded color in the fragment shader</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const drawLinesVS = `
attribute float a_id;
uniform sampler2D linesTex;
uniform vec2 linesTexDimensions;
uniform mat4 matrix;

vec4 getAs1D(sampler2D tex, vec2 dimensions, float index) {
  float y = floor(index / dimensions.x);
  float x = mod(index, dimensions.x);
  vec2 texcoord = (vec2(x, y) + 0.5) / dimensions;
  return texture2D(tex, texcoord);
}

void main() {
  // pull the position from the texture
  vec4 position = getAs1D(linesTex, linesTexDimensions, a_id);

  // do the common matrix math
  gl_Position = matrix * vec4(position.xy, 0, 1);
}
`;

const drawLinesFS = `
precision highp float;
void main() {
  gl_FragColor = vec4(vec3(0.8), 1);
}
`;
</code></pre>
<p>Finally drawing closest lines works like this</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const drawClosestLinesVS = `
attribute float a_id;
uniform float numPoints;
uniform sampler2D closestLinesTex;
uniform vec2 closestLinesTexDimensions;
uniform sampler2D linesTex;
uniform vec2 linesTexDimensions;
uniform mat4 matrix;

varying vec4 v_color;

vec4 getAs1D(sampler2D tex, vec2 dimensions, float index) {
  float y = floor(index / dimensions.x);
  float x = mod(index, dimensions.x);
  vec2 texcoord = (vec2(x, y) + 0.5) / dimensions;
  return texture2D(tex, texcoord);
}

// converts hue, saturation, and value each in the 0 to 1 range
// to rgb.  c = color, c.x = hue, c.y = saturation, c.z = value
vec3 hsv2rgb(vec3 c) {
  c = vec3(c.x, clamp(c.yz, 0.0, 1.0));
  vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
  vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
  return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
}

void main() {
  // pull the position from the texture
  float pointId = floor(a_id / 2.0);
  vec4 lineCode = getAs1D(closestLinesTex, closestLinesTexDimensions, pointId);
  float lineId = dot(lineCode, vec4(255, 256 * 255, 256 * 256 * 255, 256 * 256 * 256 * 255));
  float linePointId = lineId * 2.0 + mod(a_id, 2.0);
  vec4 position = getAs1D(linesTex, linesTexDimensions, linePointId);

  // do the common matrix math
  gl_Position = matrix * vec4(position.xy, 0, 1);
  gl_PointSize = 5.0;

  float hue = pointId / numPoints;
  v_color = vec4(hsv2rgb(vec3(hue, 1, 1)), 1);
}
`;
</code></pre>
<p>You can see it&#39;s not <em>that</em> much different from the one for points
but we need to draw 2 points per line. The starting point and the ending
point. Our id (called <code class="notranslate" translate="no">a_id</code>) above counts 0, 1, 2, 3, 4, 5, 6.... etc
so dividing by 2 gives us a <code class="notranslate" translate="no">pointId</code>.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">  float pointId = floor(a_id / 2.0);
</code></pre>
<p>We can use that to pull out the result for the corresponding point. </p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">  vec4 lineCode = getAs1D(closestLinesTex, closestLinesTexDimensions, pointId);
</code></pre>
<p>We then convert the color from the result texture back into a <code class="notranslate" translate="no">lineId</code> and use that to get either the line start or end position. </p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-glsl">float lineId = dot(lineCode, vec4(255, 256 * 255, 256 * 256 * 255, 256 * 256 * 256 * 255));
float linePointId = lineId * 2.0 + mod(a_id, 2.0);
</code></pre>
<p>Since the start and end points for a line are consecutive in our data we multiply
<code class="notranslate" translate="no">lineId</code> by 2 and then adding in <code class="notranslate" translate="no">mod(a_id, 2.0)</code> will give us either to starting
point or ending point.</p>
<p>Finally we compute a color using the same method we used when drawing points
so they&#39;ll match their points.</p>
<p>We need to compile all of these new shader programs</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const closestLinePrgInfo = webglUtils.createProgramInfo(
    gl, [closestLineVS, closestLineFS(numLineSegments)]);
+const drawLinesPrgInfo = webglUtils.createProgramInfo(
+    gl, [drawLinesVS, drawLinesFS]);
+const drawPointsPrgInfo = webglUtils.createProgramInfo(
+    gl, [drawPointsVS, drawClosestPointsLinesFS]);
+const drawClosestLinesPrgInfo = webglUtils.createProgramInfo(
+    gl, [drawClosestLinesVS, drawClosestPointsLinesFS]);
</code></pre>
<p>We also need to make a buffer of ids. We need enough ids to cover
which ever is bigger, either the number of points used for drawing points
or the number of points used for drawing lines. That way we can re-use
the same ids buffer for all programs.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// setup an id buffer
const numIds = Math.max(numPoints, numLineSegments * 2);
const ids = new Array(numIds).fill(0).map((_, i) =&gt; i);
const idBufferInfo = webglUtils.createBufferInfoFromArrays(gl, {
  id: {
    numComponents: 1,
    data: ids,
  },
});
</code></pre>
<p>So, at render time we compute the results like we did before but
we don&#39;t look up the results with <code class="notranslate" translate="no">readPixels</code>. Instead we just
pass them as a texture to the appropriate shaders.</p>
<p>First we draw all the lines in gray</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">// draw all the lines in gray
gl.bindFramebuffer(gl.FRAMEBUFFER, null);
gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);

const matrix = m4.orthographic(0, gl.canvas.width, 0, gl.canvas.height, -1, 1);

webglUtils.setBuffersAndAttributes(gl, drawLinesPrgInfo, idBufferInfo);
gl.useProgram(drawLinesPrgInfo.program);
webglUtils.setUniforms(drawLinesPrgInfo, {
  linesTex,
  linesTexDimensions,
  matrix,
});

gl.drawArrays(gl.LINES, 0, numLineSegments * 2);
</code></pre>
<p>Then we draw all the closest lines</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">webglUtils.setBuffersAndAttributes(gl, drawClosestLinesPrgInfo, idBufferInfo);
gl.useProgram(drawClosestLinesPrgInfo.program);
webglUtils.setUniforms(drawClosestLinesPrgInfo, {
  numPoints,
  closestLinesTex,
  closestLinesTexDimensions,
  linesTex,
  linesTexDimensions,
  matrix,
});

// there is one closest line for each point, 2 vertices per line
gl.drawArrays(gl.LINES, 0, numPoints * 2);
</code></pre>
<p>and finally we draw each point</p>
<pre class="prettyprint notranslate" translate="no"><code class="notranslate" translate="no">// draw the points
webglUtils.setBuffersAndAttributes(gl, drawPointsPrgInfo, idBufferInfo);
gl.useProgram(drawPointsPrgInfo.program);
webglUtils.setUniforms(drawPointsPrgInfo, {
  numPoints,
  pointsTex,
  pointsTexDimensions,
  matrix,
});
gl.drawArrays(gl.POINTS, 0, numPoints);
</code></pre><p>Before we run it lets do one more thing. Let&#39;s add more points and lines</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">-const points = [
-  100, 100, 0, 0,
-  200, 100, 0, 0,
-];
-const lines = [
-   25,  50,   0, 0,
-   25, 150,   0, 0,
-   90,  50,   0, 0,
-   90, 150,   0, 0,
-  125,  50,   0, 0,
-  125, 150,   0, 0,
-  185,  50,   0, 0,
-  185, 150,   0, 0,
-  225,  50,   0, 0,
-  225, 150,   0, 0,
-];

+function createPoints(numPoints) {
+  const points = [];
+  for (let i = 0; i &lt; numPoints; ++i) {
+    points.push(r(gl.canvas.width), r(gl.canvas.height), 0, 0);  // RGBA
+  }
+  return points;
+}
+
+const r = max =&gt; Math.random() * max;
+
+const points = createPoints(8);
+const lines = createPoints(125 * 2);

const numPoints = points.length / 4;
const numLineSegments = lines.length / 4 / 2;
</code></pre>
<p>and if we run that</p>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-closest-line.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-closest-line.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<p>You can bump up the number of points and lines
but at some point you won&#39;t be able to tell which
points go with which lines but with a smaller number
you can at least visually verify it&#39;s working.</p>
<p>Just for fun, lets combine the particle example and this
example. We&#39;ll use the techniques we used to update
the positions of particles to update the points and
line segment positions.</p>
<p>To do that we copy in the <code class="notranslate" translate="no">updatePositionFS</code> fragment shader
from the particle example and compile it. For the vertex shader
we can use the same one <code class="notranslate" translate="no">closestLineVS</code> is using as it&#39;s just
copying <code class="notranslate" translate="no">a_position</code> to <code class="notranslate" translate="no">gl_Position</code></p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const closestLinePrgInfo = webglUtils.createProgramInfo(
    gl, [closestLineVS, closestLineFS(numLineSegments)]);
const drawLinesPrgInfo = webglUtils.createProgramInfo(
    gl, [drawLinesVS, drawLinesFS]);
const drawPointsPrgInfo = webglUtils.createProgramInfo(
    gl, [drawPointsVS, drawClosestPointsLinesFS]);
const drawClosestLinesPrgInfo = webglUtils.createProgramInfo(
    gl, [drawClosestLinesVS, drawClosestPointsLinesFS]);
+const updatePositionPrgInfo = webglUtils.createProgramInfo(
+    gl, [closestLineVS, updatePositionFS]);
</code></pre>
<p>We need to generate velocities for both the points and lines</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">-function createPoints(numPoints) {
+function createPoints(numPoints, ranges) {
  const points = [];
  for (let i = 0; i &lt; numPoints; ++i) {
-    points.push(r(gl.canvas.width), r(gl.canvas.height), 0, 0);  // RGBA
+    points.push(...ranges.map(range =&gt; r(...range)), 0, 0);  // RGBA
  }
  return points;
}

-const r = max =&gt; Math.random() * max;
+const r = (min, max) =&gt; min + Math.random() * (max - min);

-const points = createPoints(8);
-const lines = createPoints(125 * 2);
+const points = createPoints(8, [[0, gl.canvas.width], [0, gl.canvas.height]]);
+const lines = createPoints(125 * 2, [[0, gl.canvas.width], [0, gl.canvas.height]]);
const numPoints = points.length / 4;
const numLineSegments = lines.length / 4 / 2;

+const pointVelocities = createPoints(numPoints, [[-20, 20], [-20, 20]]);
+const lineVelocities = createPoints(numLineSegments * 2, [[-20, 20], [-20, 20]]);
</code></pre>
<p>We need to make copies of the points and lines textures
so we have old and new versions of each so we can read from the old
and render to the new.</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">-const {tex: pointsTex, dimensions: pointsTexDimensions} =
-    createDataTexture(gl, points, gl.FLOAT);
-const {tex: linesTex, dimensions: linesTexDimensions} =
-    createDataTexture(gl, lines, gl.FLOAT);
+const {tex: pointsTex1, dimensions: pointsTexDimensions1} =
+    createDataTexture(gl, points, gl.FLOAT);
+const {tex: linesTex1, dimensions: linesTexDimensions1} =
+    createDataTexture(gl, lines, gl.FLOAT);
+const {tex: pointsTex2, dimensions: pointsTexDimensions2} =
+    createDataTexture(gl, points, gl.FLOAT);
+const {tex: linesTex2, dimensions: linesTexDimensions2} =
+    createDataTexture(gl, lines, gl.FLOAT);
</code></pre>
<p>and we need textures for the velocities</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const {tex: pointVelocityTex, dimensions: pointVelocityTexDimensions} =
    createDataTexture(gl, pointVelocities, gl.FLOAT);
const {tex: lineVelocityTex, dimensions: lineVelocityTexDimensions} =
    createDataTexture(gl, lineVelocities, gl.FLOAT);
</code></pre>
<p>We need to make framebuffers for both sets of points and lines</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const pointsFB1 = createFramebuffer(gl, pointsTex1);
const pointsFB2 = createFramebuffer(gl, pointsTex2);
const linesFB1 = createFramebuffer(gl, linesTex1);
const linesFB2 = createFramebuffer(gl, linesTex2);
</code></pre>
<p>And we need to setup some object to track old and new</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">let oldPointsLines = {
  pointsFB: pointsFB1,
  linesFB: linesFB1,
  pointsTex: pointsTex1,
  linesTex: linesTex1,
};
let newPointsLines = {
  pointsFB: pointsFB2,
  linesFB: linesFB2,
  pointsTex: pointsTex2,
  linesTex: linesTex2,
};
</code></pre>
<p>Then we need a render loop</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">const pointsTexDimensions = pointsTexDimensions1;
const linesTexDimensions = linesTexDimensions1;

let then = 0;
function render(time) {
  // convert to seconds
  time *= 0.001;
  // Subtract the previous time from the current time
  const deltaTime = time - then;
  // Remember the current time for the next frame.
  then = time;

  webglUtils.resizeCanvasToDisplaySize(gl.canvas);
</code></pre>
<p>The first thing we do in the render loop is render
the new positions from the old positions and velocities</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">  // update the point positions
  gl.bindFramebuffer(gl.FRAMEBUFFER, newPointsLines.pointsFB);
  gl.viewport(0, 0, ...pointsTexDimensions);
  webglUtils.setBuffersAndAttributes(gl, updatePositionPrgInfo, quadBufferInfo);
  gl.useProgram(updatePositionPrgInfo.program);
  webglUtils.setUniforms(updatePositionPrgInfo, {
    positionTex: oldPointsLines.pointsTex,
    texDimensions: pointsTexDimensions,
    velocityTex: pointVelocityTex,
    canvasDimensions: [gl.canvas.width, gl.canvas.height],
    deltaTime,
  });
  gl.drawArrays(gl.TRIANGLES, 0, 6);  // draw the clip space quad so we get one result for each pixel
</code></pre>
<p>and do the same for the line positions</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">  // update the line positions
  gl.bindFramebuffer(gl.FRAMEBUFFER, newPointsLines.linesFB);
  gl.viewport(0, 0, ...linesTexDimensions);
  webglUtils.setBuffersAndAttributes(gl, updatePositionPrgInfo, quadBufferInfo);
  gl.useProgram(updatePositionPrgInfo.program);
  webglUtils.setUniforms(updatePositionPrgInfo, {
    positionTex: oldPointsLines.linesTex,
    texDimensions: linesTexDimensions,
    velocityTex: lineVelocityTex,
    canvasDimensions: [gl.canvas.width, gl.canvas.height],
    deltaTime,
  });
  gl.drawArrays(gl.TRIANGLES, 0, 6);  // draw the clip space quad so we get one result for each pixel
</code></pre>
<p>With that done we can pull out which textures to use to compute closest lines
and the rest of the rendering code stays the same</p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">+  const {linesTex, pointsTex} = newPointsLines;

  ... rendering code from previous example ...
</code></pre>
<p>and finally like our particle example we swap old and new </p>
<pre class="prettyprint notranslate" translate="no"><code class="lang-js">  // swap old and new for next frame
  {
    const temp = oldPointsLines;
    oldPointsLines = newPointsLines;
    newPointsLines = temp;
  }
  requestAnimationFrame(render);
}
requestAnimationFrame(render);
</code></pre>
<p>And with that we can see it working dynamically and all the computation
is happening on the GPU</p>
<p><div class="webgl_example_container">
  <iframe class="webgl_example" style=" " src="/webgl/resources/editor.html?url=/webgl/lessons/..%2Fwebgl-gpgpu-closest-line-dynamic.html"></iframe>
  <a class="webgl_center" href="/webgl/lessons/../webgl-gpgpu-closest-line-dynamic.html" target="_blank">click here to open in a separate window</a>
</div>

</p>
<h2 id="some-caveats-about-gpgpu">Some Caveats about GPGPU</h2>
<ul>
<li><p>GPGPU in WebGL1 is mostly limited to using 2D arrays
as output though you can output to more than one 2D array
at the same time using the <code class="notranslate" translate="no">WEBGL_draw_buffers</code> extension
if it exists.</p>
<p>WebGL2 adds the ability to just process a 1D array of arbitrary size.
WebGPU (AFAIK) lets you have random access writing, ie (compute shaders).</p>
</li>
<li><p>GPUs don&#39;t have the same precision as CPUs.</p>
<p>Check your results and make sure they are acceptable.</p>
</li>
<li><p>There is overhead to GPGPU.</p>
<p>In the first two examples above we computed some
data using WebGL and then read the results. Setting up buffers, textures
setting attributes and uniforms takes time. Enough time that for anything
under a certain size it would be better to just do it in JavaScript.
The actual examples multiplying 6 numbers or adding 3 pairs of numbers
are much too small for GPGPU to be useful. Where that trade off is
is undefined. Experiment but just a guess that if you&#39;re not doing at least
1000 or more things keep it in JavaScript</p>
</li>
<li><p><code class="notranslate" translate="no">readPixels</code> is slow</p>
<p>reading the results from WebGL is slow so it&#39;s important to avoid it
as much as possible. As an example nether the particle system above nor
the dynamic closest lines example ever
read the results back to JavaScript. Where you can, keep the results
on the GPU for as long as possible. In other words, you could do something
like</p>
<ul>
<li>compute stuff on GPU</li>
<li>read result</li>
<li>prep result for next step</li>
<li>upload prepped result to gpu</li>
<li>compute stuff on GPU</li>
<li>read result</li>
<li>prep result for next step</li>
<li>upload prepped result to gpu</li>
<li>compute stuff on GPU</li>
<li>read result</li>
</ul>
<p>where as via creative solutions it would be much faster if you could</p>
<ul>
<li>compute stuff on GPU</li>
<li>prep result for next step using GPU</li>
<li>compute stuff on GPU</li>
<li>prep result for next step using GPU</li>
<li>compute stuff on GPU</li>
<li>read result</li>
</ul>
<p>Our dynamic closest lines example did this. The results never leave
the GPU.</p>
<p>As another example I once wrote a histogram computing shader. I then read
the results back into JavaScript, figured out the min and max values
Then drew the image back to the canvas using those min and max values
as uniforms to auto-level the image.</p>
<p>But, it turned instead of reading the histogram back into JavaScript
I could instead run a shader on the histogram itself that generated
a 2 pixel texture with the min and max values in the texture.</p>
<p>I could then pass that 2 pixel texture into the 3rd shader which it
could read for the min and max values. No need to read them out of the
GPU for setting uniforms.</p>
<p>Similarly to display the histogram itself I first read the histogram
data from the GPU but later I instead wrote a shader that could
visualize the histogram data directly removing the need to read it
back to JavaScript.</p>
<p>By doing that the entire process stayed on the GPU and was likely much
faster.</p>
</li>
<li><p>GPUs can do many things in parallel but most can&#39;t multi-task the same way
a CPU can. GPUs usually can&#39;t do &quot;<a href="https://www.google.com/search?q=preemptive+multitasking">preemptive multitasking</a>&quot;.
That means if you give them a very complex shader that say takes 5 minutes to
run they&#39;ll potentially freeze your entire machine for 5 minutes.
Most well made OSes deal with this by having the CPU check how long it&#39;s been
since the last command they gave to the GPU. If it&#39;s been to long (5-6 second)
and the GPU has not responded then their only option is to reset the GPU.</p>
<p>This is one reason why WebGL can lose the context and you get an &quot;Aw, rats!&quot;
or similar message.</p>
<p>It&#39;s easy to give the GPU too much to do but in graphics it&#39;s not <em>that</em>
common to take it to the 5-6 second level. It&#39;s usually more like the 0.1
second level which is still bad but usually you want graphics to run fast
and so the programmer will hopefully optimize or find a different technique
to keep the their app responsive.</p>
<p>GPGPU on the other hand you might truly want to give the GPU a heavy task
to run. There is no easy solution here. A mobile phone has a much less powerful
GPU than a top end PC. Other than doing your own timing there is no way to
know for sure how much work you can give a GPU before its &quot;too slow&quot;</p>
<p>I don&#39;t have a solution to offer. Only a warning that depending on what you&#39;re
trying to do you may run into that issue.</p>
</li>
<li><p>Mobile devices don&#39;t generally support rendering to floating point textures</p>
<p>There are no easy solutions here. One solution is you can try to
encode floating point values into RGBA/UNSIGNED_BYTE values. In the shader
when you read a value from the texture you need to convert back to
floating point and when you output a color you need to re-encode it
back into RGBA/UNSIGNED_BYTE. See <a href="https://stackoverflow.com/a/63830492/128511">this</a></p>
<p>But, for example, if we were to use this in the particle or closest line
examples above they would require significant changes. The code above
is able to pull out a position (3 values, x, y, z) with just one lookup
but now we&#39;d need to do 3 lookups. The code above is also able to write
a new 3 value position <code class="notranslate" translate="no">gl_FragColor = newPosition</code> but now we&#39;d only be 
able to write 1 value. We&#39;d either have to try to use <code class="notranslate" translate="no">WEBGL_draw_buffers</code>
to let us write out 3 values to 3 different textures (yet more work)
or we&#39;d have to adjust the shader to run 3 times, once for each of X, Y, and Z</p>
<p>One other solution is some mobile devices support rendering to half floats.
The problem with half floats are they have very little precision so while
they are useful for some problems they aren&#39;t nearly as generally useful
as normal 32bit floating point values.</p>
</li>
</ul>
<p>I hope these examples helped you understand the key idea of GPGPU in WebGL
is just the fact that WebGL reads from and writes to 2D textures which are
really 2D arrays of <strong>DATA</strong>, not just pixels for images.</p>
<p>They work similar to <code class="notranslate" translate="no">map</code> functions in that the function being called
for each value doesn&#39;t get to decide where its value will be stored.
Rather that is decided from the outside the function. In WebGL&#39;s case
that&#39;s decided by how you setup what you&#39;re drawing. Once you call <code class="notranslate" translate="no">gl.drawXXX</code>
the shader will be called for each needed value being asked &quot;what value should
I make this?&quot;</p>
<p>And that&#39;s really it.</p>
<p>The examples above mostly used 2D textures as 1D arrays but of course
you can use them as 2D arrays (for example multiplying 2 large matrices
for machine learning), or similarly to how we did math to treat 2D arrays
as 1D arrays we could also write math to treat 2D arrays as 3D arrays
and use that for things like fluid simulations.</p>

    </div>
    <div class="lesson-sidebar">
        <select class="language">
    <option value="/webgl/lessons/webgl-gpgpu.html" selected>English</a>
    <option value="/webgl/lessons/fr/webgl-gpgpu.html" >Français</a>
    <option value="/webgl/lessons/ja/webgl-gpgpu.html" >日本語</a>
    <option value="/webgl/lessons/ko/webgl-gpgpu.html" >한국어</a>
    <option value="/webgl/lessons/pl/webgl-gpgpu.html" >Polski</a>
    <option value="/webgl/lessons/pt-br/webgl-gpgpu.html" >Portuguese</a>
    <option value="/webgl/lessons/ru/webgl-gpgpu.html" >Русский</a>
    <option value="/webgl/lessons/zh_cn/webgl-gpgpu.html" >简体中文</a>
</select>


        <div id="toc">
          <ul>  <li>Fundamentals</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-fundamentals.html">Fundamentals</a></li>
<li><a href="/webgl/lessons/webgl-how-it-works.html">How It Works</a></li>
<li><a href="/webgl/lessons/webgl-shaders-and-glsl.html">Shaders and GLSL</a></li>
<li><a href="/webgl/lessons/resources/webgl-state-diagram.html">WebGL State Diagram</a></li>
        </ul>
  <li>Image Processing</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-image-processing.html">Image Processing</a></li>
<li><a href="/webgl/lessons/webgl-image-processing-continued.html">Image Processing Continued</a></li>
        </ul>
  <li>2D translation, rotation, scale, matrix math</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-2d-translation.html">2D Translation</a></li>
<li><a href="/webgl/lessons/webgl-2d-rotation.html">2D Rotation</a></li>
<li><a href="/webgl/lessons/webgl-2d-scale.html">2D Scale</a></li>
<li><a href="/webgl/lessons/webgl-2d-matrices.html">2D Matrices</a></li>
        </ul>
  <li>3D</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-3d-orthographic.html">Orthographic 3D</a></li>
<li><a href="/webgl/lessons/webgl-3d-perspective.html">3D Perspective</a></li>
<li><a href="/webgl/lessons/webgl-3d-camera.html">3D Cameras</a></li>
        </ul>
  <li>Lighting</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-3d-lighting-directional.html">Directional Lighting</a></li>
<li><a href="/webgl/lessons/webgl-3d-lighting-point.html">Point Lighting</a></li>
<li><a href="/webgl/lessons/webgl-3d-lighting-spot.html">Spot Lighting</a></li>
        </ul>
  <li>Structure and Organization</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-less-code-more-fun.html">Less Code, More Fun</a></li>
<li><a href="/webgl/lessons/webgl-drawing-multiple-things.html">Drawing Multiple Things</a></li>
<li><a href="/webgl/lessons/webgl-scene-graph.html">Scene Graphs</a></li>
        </ul>
  <li>Geometry</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-3d-geometry-lathe.html">Geometry - Lathe</a></li>
<li><a href="/webgl/lessons/webgl-load-obj.html">Loading .obj files</a></li>
<li><a href="/webgl/lessons/webgl-load-obj-w-mtl.html">Loading .obj w .mtl files</a></li>
        </ul>
  <li>Textures</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-3d-textures.html">Textures</a></li>
<li><a href="/webgl/lessons/webgl-data-textures.html">Data Textures</a></li>
<li><a href="/webgl/lessons/webgl-2-textures.html">Using 2 or More Textures</a></li>
<li><a href="/webgl/lessons/webgl-cors-permission.html">Cross Origin Images</a></li>
<li><a href="/webgl/lessons/webgl-3d-perspective-correct-texturemapping.html">Perspective Correct Texture Mapping</a></li>
<li><a href="/webgl/lessons/webgl-planar-projection-mapping.html">Planar and Perspective Projection Mapping</a></li>
        </ul>
  <li>Rendering To A Texture</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-render-to-texture.html">Render to Texture</a></li>
        </ul>
  <li>Shadows</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-shadows.html">Shadows</a></li>
        </ul>
  <li>Techniques</li>
        <ul>
            <li>2D</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-2d-drawimage.html">2D - DrawImage</a></li>
<li><a href="/webgl/lessons/webgl-2d-matrix-stack.html">2D - Matrix Stack</a></li>
<li><a href="/webgl/lessons/webgl-sprites.html">Sprites</a></li>
        </ul>
  <li>3D</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-cube-maps.html">Cubemaps</a></li>
<li><a href="/webgl/lessons/webgl-environment-maps.html">Environment maps</a></li>
<li><a href="/webgl/lessons/webgl-skybox.html">Skyboxes</a></li>
<li><a href="/webgl/lessons/webgl-skinning.html">Skinning</a></li>
<li><a href="/webgl/lessons/webgl-fog.html">Fog</a></li>
<li><a href="/webgl/lessons/webgl-picking.html">Picking (clicking on stuff)</a></li>
        </ul>
  <li>Text</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-text-html.html">Text - HTML</a></li>
<li><a href="/webgl/lessons/webgl-text-canvas2d.html">Text - Canvas 2D</a></li>
<li><a href="/webgl/lessons/webgl-text-texture.html">Text - Using a Texture</a></li>
<li><a href="/webgl/lessons/webgl-text-glyphs.html">Text - Using a Glyph Texture</a></li>
        </ul>
  <li>Textures</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-ramp-textures.html">Ramp Textures (Toon Shading)</a></li>
        </ul>
  <li>GPGPU</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-gpgpu.html">GPGPU</a></li>
        </ul>
        </ul>
  <li>Tips</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-smallest-programs.html">Smallest Programs</a></li>
<li><a href="/webgl/lessons/webgl-drawing-without-data.html">Drawing Without Data</a></li>
<li><a href="/webgl/lessons/webgl-shadertoy.html">Shadertoy</a></li>
<li><a href="/webgl/lessons/webgl-pulling-vertices.html">Pulling Vertices</a></li>
        </ul>
  <li>Optimization</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-indexed-vertices.html">Indexed Vertices (gl.drawElements)</a></li>
<li><a href="/webgl/lessons/webgl-instanced-drawing.html">Instanced Drawing</a></li>
        </ul>
  <li>Misc</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-setup-and-installation.html">Setup And Installation</a></li>
<li><a href="/webgl/lessons/webgl-boilerplate.html">Boilerplate</a></li>
<li><a href="/webgl/lessons/webgl-resizing-the-canvas.html">Resizing the Canvas</a></li>
<li><a href="/webgl/lessons/webgl-animation.html">Animation</a></li>
<li><a href="/webgl/lessons/webgl-points-lines-triangles.html">Points, Lines, and Triangles</a></li>
<li><a href="/webgl/lessons/webgl-multiple-views.html">Multiple Views, Multiple Canvases</a></li>
<li><a href="/webgl/lessons/webgl-visualizing-the-camera.html">Visualizing the Camera</a></li>
<li><a href="/webgl/lessons/webgl-and-alpha.html">WebGL and Alpha</a></li>
<li><a href="/webgl/lessons/webgl-2d-vs-3d-library.html">2D vs 3D libraries</a></li>
<li><a href="/webgl/lessons/webgl-anti-patterns.html">Anti-Patterns</a></li>
<li><a href="/webgl/lessons/webgl-matrix-vs-math.html">WebGL Matrices vs Math Matrices</a></li>
<li><a href="/webgl/lessons/webgl-precision-issues.html">Precision Issues</a></li>
<li><a href="/webgl/lessons/webgl-tips.html#screenshot">Taking a screenshot</a></li>
<li><a href="/webgl/lessons/webgl-tips.html#preservedrawingbuffer">Prevent the Canvas Being Cleared</a></li>
<li><a href="/webgl/lessons/webgl-tips.html#tabindex">Get Keyboard Input From a Canvas</a></li>
<li><a href="/webgl/lessons/webgl-tips.html#html-background">Use WebGL as Background in HTML</a></li>
<li><a href="/webgl/lessons/webgl-cross-platform-issues.html">Cross Platform Issues</a></li>
<li><a href="/webgl/lessons/webgl-qna.html">Questions and Answers</a></li>
        </ul>
  <li>Reference</li>
        <ul>
          <li><a href="/webgl/lessons/webgl-attributes.html">Attributes</a></li>
<li><a href="/webgl/lessons/webgl-texture-units.html">Texture Units</a></li>
<li><a href="/webgl/lessons/webgl-framebuffers.html">Framebuffers</a></li>
<li><a href="/webgl/lessons/webgl-readpixels.html">readPixels</a></li>
<li><a href="/webgl/lessons/webgl-references.html">References</a></li>
        </ul></ul>
<ul>
  <li><a href="/docs/">Helper API Docs</a></li>
  <li><a href="https://twgljs.org">TWGL, A tiny WebGL helper library</a></li>
  <li><a href="https://github.com/gfxfundamentals/webgl-fundamentals">github</a></li>
</ul>
        </div>
    </div>
    <div class="lesson-comments">
        
    <div>Questions? <a href="https://stackoverflow.com/questions/tagged/webgl">Ask on stackoverflow</a>.</div>
    <div>Issue/Bug? <a href="https://github.com/gfxfundamentals/webgl-fundamentals/issues">Create an issue on github</a>.</div>
    <div class="lesson-comment-notes">
       Use <b>&lt;pre&gt;&lt;code&gt;</b>code goes here<b>&lt;/code&gt;&lt;/pre&gt;</b> for code blocks
    </div>
  

        <div id="disqus_thread"></div>
        <script>
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'webglfundamentals'; // required: replace example with your forum shortname
            var disqus_identifier = 'WebGL GPGPU';
            var disqus_title = 'WebGL GPGPU';

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function() {
                if (window.location.hostname.indexOf("webglfundamentals.org") < 0) {
                    return;
                }
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
  </div>
</div>
</body>
<script>
const settings = {
  contribTemplate: "Thank you <a href=\"${html_url}\"><img src=\"${avatar_url}\"> ${login}</a><br>for <a href=\"https://github.com/${owner}/${repo}/commits?author=${login}\">${contributions} contributions</a>",
  owner: "gfxfundamentals",
  repo: "webgl-fundamentals",
};
</script>
<script src="/contributors.js"></script>
<script src="/3rdparty/jquery-1.11.2.min.js"></script>
<script src="/webgl/lessons/resources/prettify.js"></script>
<script src="/webgl/lessons/resources/lesson.js" type="module"></script>
<script>
(function() {
  if (window.location.hostname.indexOf("webglfundamentals.org") < 0) {
      return;
  }

  function addScript(src, fn) {
    const script = document.createElement('script');
    const firstScript = document.getElementsByTagName('script')[0];
    script.async = true;
    script.defer = true;
    if (fn) {
      script.addEventListener('load', fn);
    }
    script.src = src;
    firstScript.parentNode.insertBefore(script, firstScript);
  }

  addScript('//cdn.webglstats.com/stat.js');

  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59804936-1', 'auto');
  ga('send', 'pageview');
}());
</script>


</html>



